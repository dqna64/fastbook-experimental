{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /opt/conda/envs/fastai/lib/python3.8/site-packages (0.18.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from gym) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from gym) (1.19.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/fastai/lib/python3.8/site-packages (from gym) (1.5.3)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: Pillow<=7.2.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from gym) (7.2.0)\n",
      "Requirement already satisfied: future in /opt/conda/envs/fastai/lib/python3.8/site-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.18.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym.spaces import Discrete, Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:\t1.7.0\n",
      "gym version:\t0.18.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"torch version:\\t{torch.__version__}\")\n",
    "print(f\"gym version:\\t{gym.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Categorical`'s `probs` argument takes in a tensor of 'probabilities' in range `[0, inf)` ie. non-negative but does not need to sum to 1, as the class will automatically normalize the values to make the distribution. Make sure to sigmoid or softmax activations before passing this argument.\n",
    "\n",
    "`Categorical`'s `logits` argument takes a tensor of values in range `(-inf, inf)` and will turn it into a probability distribution that sums to 1, probably with softmax but idk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1628 0.1733 0.1379 0.526 ]\n"
     ]
    }
   ],
   "source": [
    "probs_list = [0.25, 0.25, 0.21, 0.80]\n",
    "dist = torch.distributions.categorical.Categorical(probs=torch.tensor(probs_list))\n",
    "classes = np.zeros(len(probs))\n",
    "iterations = 10000\n",
    "for i in range(iterations):\n",
    "    class_idx = dist.sample().item()\n",
    "    classes[class_idx] += 1\n",
    "print(f\"{classes/iterations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0597 0.1389 0.2548 0.5466]\n"
     ]
    }
   ],
   "source": [
    "logits_list = [-1.05, -0.15, 0.41, 1.20]\n",
    "dist = torch.distributions.categorical.Categorical(logits=torch.tensor(logits_list))\n",
    "classes = np.zeros(len(probs))\n",
    "iterations = 10000\n",
    "for i in range(iterations):\n",
    "    class_idx = dist.sample().item()\n",
    "    classes[class_idx] += 1\n",
    "print(f\"{classes/iterations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0580, 0.1426, 0.2496, 0.5499]),\n",
       " tensor([-2.8480, -1.9480, -1.3880, -0.5980]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.probs, dist.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init_(self, env):\n",
    "        self.n_inputs = env.observation_space.shape[0]\n",
    "        self.n_outputs = env.action_space.n\n",
    "        \n",
    "        # Define neural network\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(self.n_inputs, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, self.n_outputs),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        action_probs = self.network(torch.FloatTensor(state))\n",
    "        return action_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateMLP(sizes, hidden_act_fn=nn.ReLU, output_act_fn=nn.Softmax):\n",
    "    # Sizes consists of the sizes of all layers\n",
    "    layers = []\n",
    "    for i in range(len(sizes)-1):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite-Horizon Discounted Rewards helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discounted_rewards(rewards, gamma=0.99):\n",
    "    # rewards must be a rank 1 array of scalar reward values\n",
    "    assert len(rewards.shape) == 1\n",
    "    trajec_len = rewards.size # Number of reward values\n",
    "    discounted_rewards = np.zeros_like(rewards, dtype=np.float32)\n",
    "    for i in reversed(range(trajec_len)):\n",
    "        discounted_rewards[i] = rewards[i] + gamma * (discounted_rewards[i+1] if i+1 < trajec_len else 0)\n",
    "    return discounted_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 4, 2, 1, 3, 2, 4, 4, 4, 1, 4])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = np.random.randint(6, size=(12,))\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31., 29., 29., 25., 23., 22., 19., 17., 13.,  9.,  5.,  4.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discounted_rewards(rewards, gamma=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, model, num_episodes=150, ep_batch_size, gamma=0.99):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

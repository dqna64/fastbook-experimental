{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagenette is a subset of ImageNet consisting of images from 10 categories as opposed to the full 1000 categories of ImageNet. Enables faster iteration, so you can try out more ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.IMAGENETTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/storage/data/imagenette2/val'),Path('/storage/data/imagenette2/train')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('val'),Path('train')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datablock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                      get_items=get_image_files,\n",
    "                      get_y=parent_label,\n",
    "                      item_tfms=Resize(460),\n",
    "                      batch_tfms=aug_transforms(size=224, min_scale=0.75))\n",
    "dataloaders = datablock.dataloaders(path, bs=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a new resnet model. This will be our baseline. Note that the `xresnet50` model is not pretrained, so should not use `fine_tune` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.557460</td>\n",
       "      <td>2.346827</td>\n",
       "      <td>0.416729</td>\n",
       "      <td>02:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.212875</td>\n",
       "      <td>2.598495</td>\n",
       "      <td>0.447722</td>\n",
       "      <td>02:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.942469</td>\n",
       "      <td>1.197255</td>\n",
       "      <td>0.629948</td>\n",
       "      <td>02:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.668550</td>\n",
       "      <td>0.790889</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.574210</td>\n",
       "      <td>0.567909</td>\n",
       "      <td>0.820388</td>\n",
       "      <td>02:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = xresnet50(n_out=dataloaders.c)\n",
    "learner = Learner(dataloaders, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n",
    "learner.fit_one_cycle(5, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorImage([0.4898, 0.4815, 0.4437], device='cuda:0'),\n",
       " TensorImage([0.2862, 0.2812, 0.3122], device='cuda:0'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = dataloaders.one_batch()\n",
    "xb.mean(dim=[0, 2, 3]), xb.std(dim=[0, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `Normalize` transform and pass it the mean and standard deviation of your data so it knows how to normalize it to the standard normal distribution (mean 0, std 1). Fastai stores the standard ImageNet mean and std in `imagenet_stats`, which is okay to use for the Imagenette subset. If you don't pass any statistics to the `Normalize` tranform, fastai will automatically calculate them from a single batch of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(bs, aug_size):\n",
    "    db = DataBlock(blocks=(ImageBlock, CategoryBlock), \n",
    "                   get_items=get_image_files, \n",
    "                   get_y=parent_label, \n",
    "                   item_tfms=Resize(460), \n",
    "                   batch_tfms=[*aug_transforms(size=aug_size, min_scale=0.75),\n",
    "                               Normalize.from_stats(*imagenet_stats)]\n",
    "                  )\n",
    "    return db.dataloaders(path, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = get_dataloaders(64, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorImage([-0.0057,  0.0638,  0.1516], device='cuda:0'),\n",
       " TensorImage([1.2392, 1.2368, 1.3517], device='cuda:0'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = dataloaders.one_batch()\n",
    "xb.mean(dim=[0, 2, 3]), xb.std(dim=[0, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what effect this had on training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.571293</td>\n",
       "      <td>2.165836</td>\n",
       "      <td>0.398432</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.255483</td>\n",
       "      <td>1.439283</td>\n",
       "      <td>0.576176</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.970735</td>\n",
       "      <td>0.904502</td>\n",
       "      <td>0.714713</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.717651</td>\n",
       "      <td>0.785193</td>\n",
       "      <td>0.752427</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.599995</td>\n",
       "      <td>0.602664</td>\n",
       "      <td>0.810680</td>\n",
       "      <td>02:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = xresnet50(n_out=dataloaders.c)\n",
    "learner = Learner(dataloaders, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n",
    "learner.fit_one_cycle(5, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effects of normalization are not so apparent here, but when fine-tuning pretrained models it is important to normalize the new data to the same statistics as the old data(??????)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progressive Resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by training the model with zoomed-in regions of images. This can be considered pretraining the model prior to fine-tuning with zoomed-out images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [2/4 01:49<01:49]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.622354</td>\n",
       "      <td>2.205114</td>\n",
       "      <td>0.449216</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.263802</td>\n",
       "      <td>2.014621</td>\n",
       "      <td>0.437267</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='73' class='' max='83' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      87.95% [73/83 00:41<00:05 1.0129]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataloaders = get_dataloaders(128, 128) # Arguments are bs, aug_size\n",
    "learner = Learner(dataloaders, xresnet50(n_out=dataloaders.c), loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n",
    "learner.fit_one_cycle(4, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now replace the `DataLoaders` inside the `Learner` with zoomed-out images, and fine-tune the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.619863</td>\n",
       "      <td>0.769145</td>\n",
       "      <td>0.754668</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.617550</td>\n",
       "      <td>0.736148</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.573330</td>\n",
       "      <td>0.652837</td>\n",
       "      <td>0.789022</td>\n",
       "      <td>00:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.509342</td>\n",
       "      <td>0.567767</td>\n",
       "      <td>0.833831</td>\n",
       "      <td>00:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.461549</td>\n",
       "      <td>0.545268</td>\n",
       "      <td>0.833831</td>\n",
       "      <td>00:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.dataloaders = get_dataloaders(64, 224) # Arguments are bs, aug_size\n",
    "learner.fine_tune(5, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can repeat this with progressively more zoomed out regions of the images—but of course, you will not get any benefit by using an image size larger than the size of your images on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
